"""BGE-M3 Embedder å–®å…ƒæ¸¬è©¦ - TDD Red Phase

æ¸¬è©¦åŸºæ–¼ features/bge_m3.feature çš„ BDD è¦æ ¼
æŒ‰ç…§ CLAUDE.md çš„ TDD å·¥ä½œæµç¨‹ï¼šPhase 1 Red - å…ˆå¯«æ¸¬è©¦
"""

import pytest
import numpy as np
from unittest.mock import Mock, patch
import threading
import time


class TestBGEM3Embedding:
    """BGE-M3 Embedder æ ¸å¿ƒåŠŸèƒ½æ¸¬è©¦"""

    def test_embed_returns_1024_dimensions(self):
        """
        Scenario: åµŒå…¥å–®å€‹ä¸­æ–‡æ–‡æœ¬
        Given ä¸€å€‹ BGEM3Embedding å¯¦ä¾‹
        When æˆ‘åµŒå…¥æ–‡æœ¬ "é€™æ˜¯ä¸€å€‹æ¸¬è©¦å¥å­"
        Then æ‡‰è©²è¿”å›ä¸€å€‹ 1024 ç¶­çš„å‘é‡
        And å‘é‡çš„æ¯å€‹å…ƒç´ éƒ½æ˜¯æµ®é»æ•¸
        And å‘é‡çš„æ¯å€‹å…ƒç´ ç¯„åœåœ¨ [-1, 1] ä¹‹é–“
        """
        from src.embeddings.bge_m3 import BGEM3Embedding

        embedder = BGEM3Embedding()
        result = embedder.embed("é€™æ˜¯ä¸€å€‹æ¸¬è©¦å¥å­")

        # é©—è­‰ç¶­åº¦
        assert len(result) == 1024, f"Expected 1024 dimensions, got {len(result)}"

        # é©—è­‰å…ƒç´ é¡å‹
        assert all(isinstance(x, (float, np.floating)) for x in result), \
            "All elements should be float"

        # é©—è­‰å…ƒç´ ç¯„åœ
        assert all(-1 <= x <= 1 for x in result), \
            "All elements should be in range [-1, 1]"

    def test_embed_empty_text_raises_error(self):
        """
        Scenario: åµŒå…¥ç©ºæ–‡æœ¬æ‡‰è©²æ‹‹å‡ºéŒ¯èª¤
        Given ä¸€å€‹ BGEM3Embedding å¯¦ä¾‹
        When æˆ‘åµŒå…¥ç©ºæ–‡æœ¬ ""
        Then æ‡‰è©²æ‹‹å‡º ValueError ç•°å¸¸
        And ç•°å¸¸è¨Šæ¯æ‡‰è©²åŒ…å« "ä¸èƒ½åµŒå…¥ç©ºæ–‡æœ¬"
        """
        from src.embeddings.bge_m3 import BGEM3Embedding

        embedder = BGEM3Embedding()

        with pytest.raises(ValueError, match="ä¸èƒ½åµŒå…¥ç©ºæ–‡æœ¬"):
            embedder.embed("")

    def test_embed_long_text_truncates(self, caplog):
        """
        Scenario: åµŒå…¥è¶…é•·æ–‡æœ¬æ‡‰è©²è‡ªå‹•æˆªæ–·
        Given ä¸€å€‹ BGEM3Embedding å¯¦ä¾‹
        When æˆ‘åµŒå…¥ä¸€å€‹è¶…é 8192 token çš„é•·æ–‡æœ¬
        Then æ‡‰è©²è‡ªå‹•æˆªæ–·åˆ° 8192 token
        And æ‡‰è©²è¿”å›ä¸€å€‹ 1024 ç¶­çš„å‘é‡
        And æ‡‰è©²è¨˜éŒ„è­¦å‘Šè¨Šæ¯
        """
        from src.embeddings.bge_m3 import BGEM3Embedding

        embedder = BGEM3Embedding()

        # å‰µå»ºè¶…é•·æ–‡æœ¬ï¼ˆç´„ 10000 å€‹å­—ï¼Œé è¶… 8192 tokenï¼‰
        long_text = "äººå·¥æ™ºæ…§æŠ€è¡“æ­£åœ¨å¿«é€Ÿç™¼å±•ã€‚" * 2000

        result = embedder.embed(long_text)

        # é©—è­‰è¿”å› 1024 ç¶­å‘é‡
        assert len(result) == 1024

        # é©—è­‰è­¦å‘Šè¨Šæ¯
        assert any("æˆªæ–·" in record.message or "truncate" in record.message.lower()
                   for record in caplog.records), \
            "Should log warning about truncation"

    def test_batch_embed(self):
        """
        Scenario: æ‰¹æ¬¡åµŒå…¥å¤šå€‹æ–‡æœ¬
        Given ä¸€å€‹ BGEM3Embedding å¯¦ä¾‹
        When æˆ‘æ‰¹æ¬¡åµŒå…¥ä»¥ä¸‹æ–‡æœ¬ï¼š
          | æ–‡æœ¬                     |
          | äººå·¥æ™ºæ…§æ­£åœ¨æ”¹è®Šä¸–ç•Œ       |
          | æ©Ÿå™¨å­¸ç¿’æ˜¯ AI çš„æ ¸å¿ƒæŠ€è¡“   |
          | æ·±åº¦å­¸ç¿’æ¨å‹•äº† AI çš„ç™¼å±•   |
        Then æ‡‰è©²è¿”å›ä¸€å€‹åŒ…å« 3 å€‹å‘é‡çš„åˆ—è¡¨
        And æ¯å€‹å‘é‡éƒ½æ˜¯ 1024 ç¶­
        And æ‰€æœ‰å‘é‡çš„å…ƒç´ éƒ½æ˜¯æµ®é»æ•¸
        """
        from src.embeddings.bge_m3 import BGEM3Embedding

        embedder = BGEM3Embedding()

        texts = [
            "äººå·¥æ™ºæ…§æ­£åœ¨æ”¹è®Šä¸–ç•Œ",
            "æ©Ÿå™¨å­¸ç¿’æ˜¯ AI çš„æ ¸å¿ƒæŠ€è¡“",
            "æ·±åº¦å­¸ç¿’æ¨å‹•äº† AI çš„ç™¼å±•"
        ]

        results = embedder.batch_embed(texts)

        # é©—è­‰è¿”å› 3 å€‹å‘é‡
        assert len(results) == 3

        # é©—è­‰æ¯å€‹å‘é‡éƒ½æ˜¯ 1024 ç¶­
        for result in results:
            assert len(result) == 1024

        # é©—è­‰æ‰€æœ‰å…ƒç´ éƒ½æ˜¯æµ®é»æ•¸
        for result in results:
            assert all(isinstance(x, (float, np.floating)) for x in result)

    def test_batch_embed_empty_list(self):
        """
        Scenario: æ‰¹æ¬¡åµŒå…¥ç©ºåˆ—è¡¨æ‡‰è©²è¿”å›ç©ºåˆ—è¡¨
        Given ä¸€å€‹ BGEM3Embedding å¯¦ä¾‹
        When æˆ‘æ‰¹æ¬¡åµŒå…¥ä¸€å€‹ç©ºåˆ—è¡¨
        Then æ‡‰è©²è¿”å›ä¸€å€‹ç©ºåˆ—è¡¨
        And ä¸æ‡‰è©²æ‹‹å‡ºä»»ä½•ç•°å¸¸
        """
        from src.embeddings.bge_m3 import BGEM3Embedding

        embedder = BGEM3Embedding()

        results = embedder.batch_embed([])

        assert results == []

    def test_similar_texts_high_similarity(self):
        """
        Scenario: ç›¸ä¼¼æ–‡æœ¬æ‡‰è©²æœ‰ç›¸ä¼¼çš„å‘é‡
        Given ä¸€å€‹ BGEM3Embedding å¯¦ä¾‹
        When æˆ‘åµŒå…¥æ–‡æœ¬ "äººå·¥æ™ºæ…§"
        And æˆ‘åµŒå…¥æ–‡æœ¬ "AI æŠ€è¡“"
        Then å…©å€‹å‘é‡çš„é¤˜å¼¦ç›¸ä¼¼åº¦æ‡‰è©²å¤§æ–¼ 0.7
        """
        from src.embeddings.bge_m3 import BGEM3Embedding

        embedder = BGEM3Embedding()

        vec1 = embedder.embed("äººå·¥æ™ºæ…§")
        vec2 = embedder.embed("AI æŠ€è¡“")

        # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
        similarity = self._cosine_similarity(vec1, vec2)

        assert similarity > 0.7, \
            f"Expected similarity > 0.7 for similar texts, got {similarity}"

    def test_dissimilar_texts_low_similarity(self):
        """
        Scenario: ä¸ç›¸ä¼¼æ–‡æœ¬æ‡‰è©²æœ‰ä¸åŒçš„å‘é‡
        Given ä¸€å€‹ BGEM3Embedding å¯¦ä¾‹
        When æˆ‘åµŒå…¥æ–‡æœ¬ "äººå·¥æ™ºæ…§"
        And æˆ‘åµŒå…¥æ–‡æœ¬ "ä»Šå¤©å¤©æ°£å¾ˆå¥½"
        Then å…©å€‹å‘é‡çš„é¤˜å¼¦ç›¸ä¼¼åº¦æ‡‰è©²å°æ–¼ 0.5
        """
        from src.embeddings.bge_m3 import BGEM3Embedding

        embedder = BGEM3Embedding()

        vec1 = embedder.embed("äººå·¥æ™ºæ…§")
        vec2 = embedder.embed("ä»Šå¤©å¤©æ°£å¾ˆå¥½")

        # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
        similarity = self._cosine_similarity(vec1, vec2)

        assert similarity < 0.5, \
            f"Expected similarity < 0.5 for dissimilar texts, got {similarity}"

    @pytest.mark.parametrize("char_count", [5, 50, 500, 2000])
    def test_embed_different_lengths(self, char_count):
        """
        Scenario Outline: åµŒå…¥ä¸åŒé•·åº¦çš„æ–‡æœ¬
        Given ä¸€å€‹ BGEM3Embedding å¯¦ä¾‹
        When æˆ‘åµŒå…¥ä¸€å€‹åŒ…å« <å­—æ•¸> å€‹å­—çš„æ–‡æœ¬
        Then æ‡‰è©²è¿”å›ä¸€å€‹ 1024 ç¶­çš„å‘é‡
        And å‘é‡çš„æ¯å€‹å…ƒç´ éƒ½æ˜¯æµ®é»æ•¸

        Examples: æ–‡æœ¬é•·åº¦
          | å­—æ•¸ |
          | 5    |
          | 50   |
          | 500  |
          | 2000 |
        """
        from src.embeddings.bge_m3 import BGEM3Embedding

        embedder = BGEM3Embedding()

        # å‰µå»ºæŒ‡å®šé•·åº¦çš„æ–‡æœ¬
        text = "æ¸¬" * char_count

        result = embedder.embed(text)

        # é©—è­‰ç¶­åº¦
        assert len(result) == 1024

        # é©—è­‰å…ƒç´ é¡å‹
        assert all(isinstance(x, (float, np.floating)) for x in result)

    def test_model_configuration(self):
        """
        Scenario: é©—è­‰æ¨¡å‹é…ç½®
        Given ä¸€å€‹ BGEM3Embedding å¯¦ä¾‹
        Then æ¨¡å‹åç¨±æ‡‰è©²æ˜¯ "BAAI/bge-m3"
        And æ‡‰è©²ä½¿ç”¨ FP16 ç²¾åº¦
        And æ‡‰è©²é‹è¡Œåœ¨ CPU ä¸Š
        And æœ€å¤§åºåˆ—é•·åº¦æ‡‰è©²æ˜¯ 8192
        """
        from src.embeddings.bge_m3 import BGEM3Embedding

        embedder = BGEM3Embedding()

        # é©—è­‰æ¨¡å‹åç¨±
        assert embedder.model_name == "BAAI/bge-m3"

        # é©—è­‰ FP16 ç²¾åº¦
        assert embedder.use_fp16 is True

        # é©—è­‰è¨­å‚™ï¼ˆCPUï¼‰
        assert embedder.device == "cpu"

        # é©—è­‰æœ€å¤§åºåˆ—é•·åº¦
        assert embedder.max_length == 8192

    def test_concurrent_embedding(self):
        """
        Scenario: å¤šç·šç¨‹ä¸¦ç™¼åµŒå…¥
        Given ä¸€å€‹ BGEM3Embedding å¯¦ä¾‹
        When æˆ‘åœ¨ 4 å€‹ç·šç¨‹ä¸­åŒæ™‚åµŒå…¥ä¸åŒçš„æ–‡æœ¬
        Then æ‰€æœ‰åµŒå…¥æ“ä½œéƒ½æ‡‰è©²æˆåŠŸ
        And è¿”å›çš„å‘é‡æ‡‰è©²æ˜¯ç¢ºå®šæ€§çš„ï¼ˆç›¸åŒæ–‡æœ¬ç¸½æ˜¯è¿”å›ç›¸åŒå‘é‡ï¼‰
        """
        from src.embeddings.bge_m3 import BGEM3Embedding

        embedder = BGEM3Embedding()

        texts = [
            "äººå·¥æ™ºæ…§",
            "æ©Ÿå™¨å­¸ç¿’",
            "æ·±åº¦å­¸ç¿’",
            "è‡ªç„¶èªè¨€è™•ç†"
        ]

        results = {}

        def embed_text(text):
            results[text] = embedder.embed(text)

        # å‰µå»º 4 å€‹ç·šç¨‹
        threads = [threading.Thread(target=embed_text, args=(text,))
                   for text in texts]

        # å•Ÿå‹•æ‰€æœ‰ç·šç¨‹
        for thread in threads:
            thread.start()

        # ç­‰å¾…æ‰€æœ‰ç·šç¨‹å®Œæˆ
        for thread in threads:
            thread.join()

        # é©—è­‰æ‰€æœ‰æ–‡æœ¬éƒ½æˆåŠŸåµŒå…¥
        assert len(results) == 4

        # é©—è­‰ç¢ºå®šæ€§ï¼ˆåŒä¸€æ–‡æœ¬å¤šæ¬¡åµŒå…¥çµæœç›¸åŒï¼‰
        for text in texts:
            vec1 = results[text]
            vec2 = embedder.embed(text)

            # ä½¿ç”¨ numpy.allclose æª¢æŸ¥å‘é‡æ˜¯å¦ç›¸åŒï¼ˆå…è¨±æµ®é»èª¤å·®ï¼‰
            assert np.allclose(vec1, vec2, rtol=1e-5), \
                f"Text '{text}' should produce deterministic embeddings"

    def test_memory_performance(self):
        """
        Scenario: è¨˜æ†¶é«”æ•ˆèƒ½é©—è­‰
        Given ä¸€å€‹ BGEM3Embedding å¯¦ä¾‹
        When æˆ‘æ‰¹æ¬¡åµŒå…¥ 100 å€‹æ–‡æœ¬
        Then è¨˜æ†¶é«”ä½¿ç”¨é‡ä¸æ‡‰è©²è¶…é 2GB
        And æ‰€æœ‰åµŒå…¥æ“ä½œéƒ½æ‡‰è©²åœ¨ 30 ç§’å…§å®Œæˆ
        """
        from src.embeddings.bge_m3 import BGEM3Embedding
        import psutil
        import os

        embedder = BGEM3Embedding()

        # æº–å‚™ 100 å€‹æ¸¬è©¦æ–‡æœ¬
        texts = [f"é€™æ˜¯ç¬¬ {i} å€‹æ¸¬è©¦æ–‡æœ¬ï¼Œç”¨æ–¼é©—è­‰è¨˜æ†¶é«”æ•ˆèƒ½ã€‚" for i in range(100)]

        # è¨˜éŒ„é–‹å§‹æ™‚é–“å’Œè¨˜æ†¶é«”
        start_time = time.time()
        process = psutil.Process(os.getpid())
        start_memory = process.memory_info().rss / (1024 ** 3)  # GB

        # åŸ·è¡Œæ‰¹æ¬¡åµŒå…¥
        results = embedder.batch_embed(texts)

        # è¨˜éŒ„çµæŸæ™‚é–“å’Œè¨˜æ†¶é«”
        end_time = time.time()
        end_memory = process.memory_info().rss / (1024 ** 3)  # GB

        elapsed_time = end_time - start_time
        memory_used = end_memory - start_memory

        # é©—è­‰æ‰€æœ‰åµŒå…¥æˆåŠŸ
        assert len(results) == 100

        # é©—è­‰æ™‚é–“æ•ˆèƒ½ï¼ˆ30 ç§’å…§å®Œæˆï¼‰
        assert elapsed_time < 30, \
            f"Expected < 30s, took {elapsed_time:.2f}s"

        # é©—è­‰è¨˜æ†¶é«”æ•ˆèƒ½ï¼ˆä¸è¶…é 2GBï¼‰
        assert memory_used < 2.0, \
            f"Expected < 2GB memory usage, used {memory_used:.2f}GB"

    @pytest.mark.performance
    def test_batch_processing_performance(self):
        """
        Scenario: æ‰¹æ¬¡è™•ç†æ•ˆèƒ½å„ªåŒ–
        Given ä¸€å€‹ BGEM3Embedding å¯¦ä¾‹
        When æˆ‘ä½¿ç”¨ batch_size=256 æ‰¹æ¬¡åµŒå…¥ 1000 å€‹æ–‡æœ¬
        Then å¹³å‡æ¯å€‹æ–‡æœ¬çš„åµŒå…¥æ™‚é–“æ‡‰è©²å°æ–¼ 50ms
        And æ‰¹æ¬¡è™•ç†æ‡‰è©²æ¯”é€å€‹è™•ç†å¿«è‡³å°‘ 5 å€
        """
        from src.embeddings.bge_m3 import BGEM3Embedding

        embedder = BGEM3Embedding()

        # æº–å‚™ 1000 å€‹æ¸¬è©¦æ–‡æœ¬ï¼ˆä½¿ç”¨è¼ƒçŸ­æ–‡æœ¬ä»¥åŠ å¿«æ¸¬è©¦é€Ÿåº¦ï¼‰
        texts = [f"æ¸¬è©¦æ–‡æœ¬ {i}" for i in range(1000)]

        # æ¸¬è©¦æ‰¹æ¬¡è™•ç†æ™‚é–“
        start_batch = time.time()
        batch_results = embedder.batch_embed(texts, batch_size=256)
        batch_time = time.time() - start_batch

        # æ¸¬è©¦é€å€‹è™•ç†æ™‚é–“ï¼ˆåªæ¸¬è©¦å‰ 100 å€‹ä»¥ç¯€çœæ™‚é–“ï¼‰
        start_single = time.time()
        for text in texts[:100]:
            embedder.embed(text)
        single_time = (time.time() - start_single) * 10  # ä¼°ç®— 1000 å€‹çš„æ™‚é–“

        # é©—è­‰æ‰¹æ¬¡è™•ç†æˆåŠŸ
        assert len(batch_results) == 1000

        # é©—è­‰å¹³å‡æ™‚é–“ï¼ˆ50ms per textï¼‰
        avg_time_ms = (batch_time / 1000) * 1000
        assert avg_time_ms < 50, \
            f"Expected < 50ms per text, got {avg_time_ms:.2f}ms"

        # é©—è­‰æ‰¹æ¬¡è™•ç†æ¯”é€å€‹è™•ç†å¿«è‡³å°‘ 5 å€
        speedup = single_time / batch_time
        assert speedup >= 5, \
            f"Expected batch processing â‰¥5x faster, got {speedup:.2f}x"

    @staticmethod
    def _cosine_similarity(vec1, vec2):
        """è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦"""
        vec1 = np.array(vec1)
        vec2 = np.array(vec2)

        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)

        return dot_product / (norm1 * norm2)


class TestBGEM3EmbeddingEdgeCases:
    """BGE-M3 Embedder é‚Šç•Œæƒ…æ³æ¸¬è©¦"""

    def test_embed_special_characters(self):
        """æ¸¬è©¦ç‰¹æ®Šå­—å…ƒåµŒå…¥"""
        from src.embeddings.bge_m3 import BGEM3Embedding

        embedder = BGEM3Embedding()

        # æ¸¬è©¦ emoji
        result = embedder.embed("é€™æ˜¯æ¸¬è©¦ ğŸ˜€ ğŸ‰")
        assert len(result) == 1024

        # æ¸¬è©¦æ¨™é»ç¬¦è™Ÿ
        result = embedder.embed("ï¼@#$%^&*ï¼ˆï¼‰ã€ã€‘")
        assert len(result) == 1024

    def test_embed_mixed_language(self):
        """æ¸¬è©¦ä¸­è‹±æ··åˆæ–‡æœ¬"""
        from src.embeddings.bge_m3 import BGEM3Embedding

        embedder = BGEM3Embedding()

        result = embedder.embed("äººå·¥æ™ºæ…§ Artificial Intelligence AI")
        assert len(result) == 1024

    def test_embed_numbers_only(self):
        """æ¸¬è©¦ç´”æ•¸å­—æ–‡æœ¬"""
        from src.embeddings.bge_m3 import BGEM3Embedding

        embedder = BGEM3Embedding()

        result = embedder.embed("123456789")
        assert len(result) == 1024

    def test_batch_embed_with_duplicates(self):
        """æ¸¬è©¦æ‰¹æ¬¡åµŒå…¥åŒ…å«é‡è¤‡æ–‡æœ¬"""
        from src.embeddings.bge_m3 import BGEM3Embedding

        embedder = BGEM3Embedding()

        texts = ["æ¸¬è©¦", "æ¸¬è©¦", "ä¸åŒ"]
        results = embedder.batch_embed(texts)

        # é©—è­‰è¿”å› 3 å€‹å‘é‡
        assert len(results) == 3

        # é©—è­‰å‰å…©å€‹å‘é‡ç›¸åŒï¼ˆç¢ºå®šæ€§ï¼‰
        assert np.allclose(results[0], results[1], rtol=1e-5)

        # é©—è­‰ç¬¬ä¸‰å€‹å‘é‡ä¸åŒ
        similarity = np.dot(results[0], results[2]) / \
                     (np.linalg.norm(results[0]) * np.linalg.norm(results[2]))
        assert similarity < 0.99  # ä¸å®Œå…¨ç›¸åŒ
